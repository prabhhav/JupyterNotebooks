{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [conda root]",
      "language": "python",
      "name": "conda-root-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.12"
    },
    "colab": {
      "name": "CaseStudy_MarketingCampaign.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prabhhav/JupyterNotebooks/blob/main/CaseStudy_MarketingCampaign.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_F9hPF-6oYcv"
      },
      "source": [
        "#Load libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from fancyimpute import KNN   \n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import chi2_contingency\n",
        "import seaborn as sns\n",
        "from random import randrange, uniform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_fuID6woYc_"
      },
      "source": [
        "#Set working directory\n",
        "os.chdir(\"E:\\Others\\Edwisor\\ContentRevamp\\MarketingCampaign\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J1AJbLjoYdB"
      },
      "source": [
        "#Load data\n",
        "marketing_train = pd.read_csv(\"marketing_tr.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jevY_nj9oYdC"
      },
      "source": [
        "#Exploratory Data Analysis\n",
        "marketing_train['schooling'] = marketing_train['schooling'].replace(\"illiterate\", \"unknown\")\n",
        "marketing_train['schooling'] = marketing_train['schooling'].replace([\"basic.4y\",\"basic.6y\",\"basic.9y\",\"high.school\",\"professional.course\"], \"high.school\")\n",
        "marketing_train['default'] = marketing_train['default'].replace(\"yes\", \"unknown\")\n",
        "marketing_train['marital'] = marketing_train['marital'].replace(\"unknown\", \"married\")\n",
        "marketing_train['month'] = marketing_train['month'].replace([\"sep\",\"oct\",\"mar\",\"dec\"], \"dec\")\n",
        "marketing_train['month'] = marketing_train['month'].replace([\"aug\",\"jul\",\"jun\",\"may\",\"nov\"], \"jun\")\n",
        "marketing_train['loan'] = marketing_train['loan'].replace(\"unknown\", \"no\")\n",
        "marketing_train['profession'] = marketing_train['profession'].replace([\"management\",\"unknown\",\"unemployed\",\"admin.\"], \"admin.\")\n",
        "marketing_train['profession'] = marketing_train['profession'].replace([\"blue-collar\",\"housemaid\",\"services\",\"self-employed\",\"entrepreneur\",\"technician\"], \"blue-collar\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GgFqLBCoYdD"
      },
      "source": [
        "## Missing Value Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "V5jGkHQ7oYdD"
      },
      "source": [
        "#Create dataframe with missing percentage\n",
        "missing_val = pd.DataFrame(marketing_train.isnull().sum())\n",
        "\n",
        "#Reset index\n",
        "missing_val = missing_val.reset_index()\n",
        "\n",
        "#Rename variable\n",
        "missing_val = missing_val.rename(columns = {'index': 'Variables', 0: 'Missing_percentage'})\n",
        "\n",
        "#Calculate percentage\n",
        "missing_val['Missing_percentage'] = (missing_val['Missing_percentage']/len(marketing_train))*100\n",
        "\n",
        "#descending order\n",
        "missing_val = missing_val.sort_values('Missing_percentage', ascending = False).reset_index(drop = True)\n",
        "\n",
        "#save output results \n",
        "missing_val.to_csv(\"Miising_perc.csv\", inex = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "3-rf8TphoYdE"
      },
      "source": [
        "#imputation method\n",
        "#Actual value = 29\n",
        "#Mean = 40.01\n",
        "#Median = 38\n",
        "#KNN = 29.35\n",
        "\n",
        "#create missing value\n",
        "#marketing_train['custAge'].loc[70] = np.nan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgxK-pYioYdF"
      },
      "source": [
        "#Impute with mean\n",
        "#marketing_train['custAge'] = marketing_train['custAge'].fillna(marketing_train['custAge'].mean())\n",
        "\n",
        "#Impute with median\n",
        "#marketing_train['custAge'] = marketing_train['custAge'].fillna(marketing_train['custAge'].median())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpkbxVOboYdF"
      },
      "source": [
        "#KNN imputation\n",
        "#Assigning levels to the categories\n",
        "lis = []\n",
        "for i in range(0, marketing_train.shape[1]):\n",
        "    #print(i)\n",
        "    if(marketing_train.iloc[:,i].dtypes == 'object'):\n",
        "        marketing_train.iloc[:,i] = pd.Categorical(marketing_train.iloc[:,i])\n",
        "        #print(marketing_train[[i]])\n",
        "        marketing_train.iloc[:,i] = marketing_train.iloc[:,i].cat.codes \n",
        "        marketing_train.iloc[:,i] = marketing_train.iloc[:,i].astype('object')\n",
        "        \n",
        "        lis.append(marketing_train.columns[i])\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "xytTxLUWoYdG"
      },
      "source": [
        "#replace -1 with NA to impute\n",
        "for i in range(0, marketing_train.shape[1]):\n",
        "    marketing_train.iloc[:,i] = marketing_train.iloc[:,i].replace(-1, np.nan) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmM3uTG9oYdH"
      },
      "source": [
        "#Apply KNN imputation algorithm\n",
        "marketing_train = pd.DataFrame(KNN(k = 3).complete(marketing_train), columns = marketing_train.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sseu6XY0oYdH"
      },
      "source": [
        "#Convert into proper datatypes\n",
        "for i in lis:\n",
        "    marketing_train.loc[:,i] = marketing_train.loc[:,i].round()\n",
        "    marketing_train.loc[:,i] = marketing_train.loc[:,i].astype('object')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "-uzTDJEeoYdI"
      },
      "source": [
        "## Outlier Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "wZdTyf2qoYdI"
      },
      "source": [
        "#df = marketing_train.copy()\n",
        "#marketing_train = df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "_c0tIzNcoYdJ"
      },
      "source": [
        "# #Plot boxplot to visualize Outliers\n",
        "# %matplotlib inline  \n",
        "# plt.boxplot(marketing_train['custAge'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "y3iF7NBeoYdL"
      },
      "source": [
        "#save numeric names\n",
        "cnames =  [\"custAge\", \"campaign\", \"pdays\", \"previous\", \"emp.var.rate\", \"cons.price.idx\", \"cons.conf.idx\", \"euribor3m\",\n",
        "           \"nr.employed\", \"pmonths\", \"pastEmail\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "4WG6U70_oYdO"
      },
      "source": [
        "# #Detect and delete outliers from data\n",
        "# for i in cnames:\n",
        "#     print(i)\n",
        "#     q75, q25 = np.percentile(marketing_train.loc[:,i], [75 ,25])\n",
        "#     iqr = q75 - q25\n",
        "\n",
        "#     min = q25 - (iqr*1.5)\n",
        "#     max = q75 + (iqr*1.5)\n",
        "#     print(min)\n",
        "#     print(max)\n",
        "    \n",
        "#     marketing_train = marketing_train.drop(marketing_train[marketing_train.loc[:,i] < min].index)\n",
        "#     marketing_train = marketing_train.drop(marketing_train[marketing_train.loc[:,i] > max].index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjy0Mne4oYdO"
      },
      "source": [
        "#Detect and replace with NA\n",
        "# #Extract quartiles\n",
        "# q75, q25 = np.percentile(marketing_train['custAge'], [75 ,25])\n",
        "\n",
        "# #Calculate IQR\n",
        "# iqr = q75 - q25\n",
        "\n",
        "# #Calculate inner and outer fence\n",
        "# minimum = q25 - (iqr*1.5)\n",
        "# maximum = q75 + (iqr*1.5)\n",
        "\n",
        "# #Replace with NA\n",
        "# marketing_train.loc[marketing_train['custAge'] < minimum,:'custAge'] = np.nan\n",
        "# marketing_train.loc[marketing_train['custAge'] > maximum,:'custAge'] = np.nan\n",
        "\n",
        "# #Calculate missing value\n",
        "# missing_val = pd.DataFrame(marketing_train.isnull().sum())\n",
        "\n",
        "# #Impute with KNN\n",
        "# marketing_train = pd.DataFrame(KNN(k = 3).complete(marketing_train), columns = marketing_train.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Euc-9OGeoYdP"
      },
      "source": [
        "## Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uwtV2HcoYdQ"
      },
      "source": [
        "##Correlation analysis\n",
        "#Correlation plot\n",
        "df_corr = marketing_train.loc[:,cnames]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9epsxs0oYdR"
      },
      "source": [
        "#Set the width and hieght of the plot\n",
        "f, ax = plt.subplots(figsize=(7, 5))\n",
        "\n",
        "#Generate correlation matrix\n",
        "corr = df_corr.corr()\n",
        "\n",
        "#Plot using seaborn library\n",
        "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
        "            square=True, ax=ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "h13tm1LAoYdS"
      },
      "source": [
        "#Chisquare test of independence\n",
        "#Save categorical variables\n",
        "cat_names = [\"profession\", \"marital\", \"schooling\", \"default\", \"housing\", \"loan\", \"contact\", \"month\", \"day_of_week\", \"poutcome\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "WkeqV6QeoYdT"
      },
      "source": [
        "#loop for chi square values\n",
        "for i in cat_names:\n",
        "    print(i)\n",
        "    chi2, p, dof, ex = chi2_contingency(pd.crosstab(marketing_train['responded'], marketing_train[i]))\n",
        "    print(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yw69bgOoYdV"
      },
      "source": [
        "marketing_train = marketing_train.drop(['pdays', 'emp.var.rate', 'day_of_week', 'loan', 'housing'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmIe_2CooYdW"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ecl69O4boYdW"
      },
      "source": [
        "#df = marketing_train.copy()\n",
        "#marketing_train = df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "6FIMkSPsoYdX"
      },
      "source": [
        "#Normality check\n",
        "%matplotlib inline  \n",
        "plt.hist(marketing_train['campaign'], bins='auto')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ifZgG8USoYdX"
      },
      "source": [
        "cnames = [\"custAge\",\"campaign\",\"previous\",\"cons.price.idx\",\"cons.conf.idx\",\"euribor3m\",\"nr.employed\",\n",
        "           \"pmonths\",\"pastEmail\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKDZ0wEboYdX"
      },
      "source": [
        "#Nomalisation\n",
        "for i in cnames:\n",
        "    print(i)\n",
        "    marketing_train[i] = (marketing_train[i] - min(marketing_train[i]))/(max(marketing_train[i]) - min(marketing_train[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9ws8EKroYdY"
      },
      "source": [
        "# #Standarisation\n",
        "# for i in cnames:\n",
        "#     print(i)\n",
        "#     marketing_train[i] = (marketing_train[i] - marketing_train[i].mean())/marketing_train[i].std()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0vR0nq_oYda"
      },
      "source": [
        "## Sampling Techniques"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1la9v3rKoYdb"
      },
      "source": [
        "##Simple random sampling\n",
        "#Sim_Sampling = marketing_train.sample(5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "I-brZf6roYdc"
      },
      "source": [
        "# ##Systematic Sampling\n",
        "# #Calculate the K value\n",
        "# k = len(marketing_train)/3500\n",
        "\n",
        "# # Generate a random number using simple random sampling\n",
        "# RandNum = randrange(0, 5)\n",
        "\n",
        "# #select Kth observation starting from RandNum\n",
        "# Sys_Sampling = marketing_train.iloc[RandNum::k, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97px1giFoYdd"
      },
      "source": [
        "# #Stratified sampling\n",
        "# from sklearn.cross_validation import train_test_split\n",
        "\n",
        "# #Select categorical variable\n",
        "# y = marketing_train['profession']\n",
        "\n",
        "#select subset using stratified Sampling\n",
        "#Rest, Sample = train_test_split(marketing_train, test_size = 0.6, stratify = y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZpkOZwIoYdi"
      },
      "source": [
        "#marketing_train = pd.read_csv(\"marketing_train_Model.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5JBbtN9oYdj"
      },
      "source": [
        "## Model Development"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj2dY-OhoYdj"
      },
      "source": [
        "#Import Libraries for decision tree\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.cross_validation import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "AbSO9wl9oYdj"
      },
      "source": [
        "#replace target categories with Yes or No\n",
        "marketing_train['responded'] = marketing_train['responded'].replace(0, 'No')\n",
        "marketing_train['responded'] = marketing_train['responded'].replace(1, 'Yes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UHs9oPxoYdj"
      },
      "source": [
        "#Divide data into train and test\n",
        "X = marketing_train.values[:, 0:16]\n",
        "Y = marketing_train.values[:,16]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EceJ7oQioYdk"
      },
      "source": [
        "#Decision Tree\n",
        "C50_model = tree.DecisionTreeClassifier(criterion='entropy').fit(X_train, y_train)\n",
        "\n",
        "#predict new test cases\n",
        "C50_Predictions = C50_model.predict(X_test)\n",
        "\n",
        "#Create dot file to visualise tree  #http://webgraphviz.com/\n",
        "# dotfile = open(\"pt.dot\", 'w')\n",
        "# df = tree.export_graphviz(C50_model, out_file=dotfile, feature_names = marketing_train.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yub6v2JyoYdk"
      },
      "source": [
        "#build confusion matrix\n",
        "# from sklearn.metrics import confusion_matrix \n",
        "# CM = confusion_matrix(y_test, y_pred)\n",
        "CM = pd.crosstab(y_test, C50_Predictions)\n",
        "\n",
        "#let us save TP, TN, FP, FN\n",
        "TN = CM.iloc[0,0]\n",
        "FN = CM.iloc[1,0]\n",
        "TP = CM.iloc[1,1]\n",
        "FP = CM.iloc[0,1]\n",
        "\n",
        "#check accuracy of model\n",
        "#accuracy_score(y_test, y_pred)*100\n",
        "((TP+TN)*100)/(TP+TN+FP+FN)\n",
        "\n",
        "#False Negative rate \n",
        "#(FN*100)/(FN+TP)\n",
        "\n",
        "#Results\n",
        "#Accuracy: 84.49\n",
        "#FNR: 63"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "8FMl2pSgoYdl"
      },
      "source": [
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "RF_model = RandomForestClassifier(n_estimators = 20).fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "NyWx2HXfoYdl"
      },
      "source": [
        "RF_Predictions = RF_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I_VBLjNoYdl"
      },
      "source": [
        "#build confusion matrix\n",
        "# from sklearn.metrics import confusion_matrix \n",
        "# CM = confusion_matrix(y_test, y_pred)\n",
        "CM = pd.crosstab(y_test, RF_Predictions)\n",
        "\n",
        "#let us save TP, TN, FP, FN\n",
        "TN = CM.iloc[0,0]\n",
        "FN = CM.iloc[1,0]\n",
        "TP = CM.iloc[1,1]\n",
        "FP = CM.iloc[0,1]\n",
        "\n",
        "#check accuracy of model\n",
        "#accuracy_score(y_test, y_pred)*100\n",
        "((TP+TN)*100)/(TP+TN+FP+FN)\n",
        "\n",
        "#False Negative rate \n",
        "#(FN*100)/(FN+TP)\n",
        "\n",
        "#Accuracy: 88\n",
        "#FNR: 67"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "4VWM2t8qoYdm"
      },
      "source": [
        "#Let us prepare data for logistic regression\n",
        "#replace target categories with Yes or No\n",
        "marketing_train['responded'] = marketing_train['responded'].replace('No', 0)\n",
        "marketing_train['responded'] = marketing_train['responded'].replace('Yes', 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "sbjEw2b9oYdn"
      },
      "source": [
        "#Create logistic data. Save target variable first\n",
        "marketing_train_logit = pd.DataFrame(marketing_train['responded'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "TM6FtrrzoYdn"
      },
      "source": [
        "#Add continous variables\n",
        "marketing_train_logit = marketing_train_logit.join(marketing_train[cnames])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK1LMEBsoYdo"
      },
      "source": [
        "marketing_train_logit.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "y28Z5d3coYdo"
      },
      "source": [
        "##Create dummies for categorical variables\n",
        "cat_names = [\"profession\", \"marital\", \"schooling\", \"default\", \"contact\", \"month\", \"poutcome\"]\n",
        "\n",
        "for i in cat_names:\n",
        "    temp = pd.get_dummies(marketing_train[i], prefix = i)\n",
        "    marketing_train_logit = marketing_train_logit.join(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ZKZlfxYioYdp"
      },
      "source": [
        "Sample_Index = np.random.rand(len(marketing_train_logit)) < 0.8\n",
        "\n",
        "train = marketing_train_logit[Sample_Index]\n",
        "test = marketing_train_logit[~Sample_Index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "gtxZSwXfoYdp"
      },
      "source": [
        "#select column indexes for independent variables\n",
        "train_cols = train.columns[1:30]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1q92vCRoYdq"
      },
      "source": [
        "#Built Logistic Regression\n",
        "import statsmodels.api as sm\n",
        "\n",
        "logit = sm.Logit(train['responded'], train[train_cols]).fit()\n",
        "\n",
        "logit.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "PTvezSvwoYdq"
      },
      "source": [
        "#Predict test data\n",
        "test['Actual_prob'] = logit.predict(test[train_cols])\n",
        "\n",
        "test['ActualVal'] = 1\n",
        "test.loc[test.Actual_prob < 0.5, 'ActualVal'] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9afBaeOhoYdr"
      },
      "source": [
        "#Build confusion matrix\n",
        "CM = pd.crosstab(test['responded'], test['ActualVal'])\n",
        "\n",
        "#let us save TP, TN, FP, FN\n",
        "TN = CM.iloc[0,0]\n",
        "FN = CM.iloc[1,0]\n",
        "TP = CM.iloc[1,1]\n",
        "FP = CM.iloc[0,1]\n",
        "\n",
        "#check accuracy of model\n",
        "#accuracy_score(y_test, y_pred)*100\n",
        "((TP+TN)*100)/(TP+TN+FP+FN)\n",
        "\n",
        "(FN*100)/(FN+TP)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "sQQqPmkZoYdr"
      },
      "source": [
        "#Accuracy: 90\n",
        "#FNR: 74"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "H-s4OEeOoYdr"
      },
      "source": [
        "#KNN implementation\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "KNN_model = KNeighborsClassifier(n_neighbors = 9).fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "da6S-uYHoYds"
      },
      "source": [
        "#predict test cases\n",
        "KNN_Predictions = KNN_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO5hxHpKoYds"
      },
      "source": [
        "#build confusion matrix\n",
        "CM = pd.crosstab(y_test, KNN_Predictions)\n",
        "\n",
        "#let us save TP, TN, FP, FN\n",
        "TN = CM.iloc[0,0]\n",
        "FN = CM.iloc[1,0]\n",
        "TP = CM.iloc[1,1]\n",
        "FP = CM.iloc[0,1]\n",
        "\n",
        "#check accuracy of model\n",
        "#accuracy_score(y_test, y_pred)*100\n",
        "((TP+TN)*100)/(TP+TN+FP+FN)\n",
        "\n",
        "#False Negative rate \n",
        "(FN*100)/(FN+TP)\n",
        "\n",
        "#Accuracy: 89\n",
        "#FNR: 76"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "RZaSE-K-oYds"
      },
      "source": [
        "#Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "#Naive Bayes implementation\n",
        "NB_model = GaussianNB().fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "CU_Xv0GaoYdt"
      },
      "source": [
        "#predict test cases\n",
        "NB_Predictions = NB_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcTXeJPHoYdt"
      },
      "source": [
        "#Build confusion matrix\n",
        "CM = pd.crosstab(y_test, NB_Predictions)\n",
        "\n",
        "#let us save TP, TN, FP, FN\n",
        "TN = CM.iloc[0,0]\n",
        "FN = CM.iloc[1,0]\n",
        "TP = CM.iloc[1,1]\n",
        "FP = CM.iloc[0,1]\n",
        "\n",
        "#check accuracy of model\n",
        "#accuracy_score(y_test, y_pred)*100\n",
        "#((TP+TN)*100)/(TP+TN+FP+FN)\n",
        "\n",
        "#False Negative rate \n",
        "(FN*100)/(FN+TP)\n",
        "\n",
        "#Accuracy: 81\n",
        "#FNR: 40"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HySJyQs3oYdt"
      },
      "source": [
        "## Cluster Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqPSKhVroYdu"
      },
      "source": [
        "#Load data\n",
        "df = pd.read_csv(\"df.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff1xVCr9oYdv"
      },
      "source": [
        "#Load required libraries\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "#Estimate optimum number of clusters\n",
        "cluster_range = range( 1, 20 )\n",
        "cluster_errors = []\n",
        "\n",
        "for num_clusters in cluster_range:\n",
        "    clusters = KMeans(num_clusters).fit(df.iloc[:,0:4])\n",
        "    cluster_errors.append(clusters.inertia_)\n",
        "    \n",
        "#Create dataframe with cluster errors\n",
        "clusters_df = pd.DataFrame( { \"num_clusters\":cluster_range, \"cluster_errors\": cluster_errors } )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcM9SrXxoYdv"
      },
      "source": [
        "#Plot line chart to visualise number of clusters\n",
        "%matplotlib inline  \n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot( clusters_df.num_clusters, clusters_df.cluster_errors, marker = \"o\" )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "CLIEqxfnoYdw"
      },
      "source": [
        "#Implement kmeans\n",
        "kmeans_model = KMeans(n_clusters = 3).fit(df.iloc[:,0:4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn7fcQRdoYdw"
      },
      "source": [
        "#Summarize output\n",
        "pd.crosstab(df['Species'], kmeans_model.labels_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "TvnUX_vsoYdx"
      },
      "source": [
        "cluster_range = range( 1, 20 )\n",
        "cluster_errors = []\n",
        "\n",
        "for num_clusters in cluster_range:\n",
        "    clusters = KMeans( num_clusters )\n",
        "    clusters.fit( df.iloc[:,0:4] )\n",
        "    cluster_errors.append( clusters.inertia_ )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "iqux09rHoYdx"
      },
      "source": [
        "clusters_df = pd.DataFrame( { \"num_clusters\":cluster_range, \"cluster_errors\": cluster_errors } )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF90rP_ioYdx"
      },
      "source": [
        "%matplotlib inline  \n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot( clusters_df.num_clusters, clusters_df.cluster_errors, marker = \"o\" )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}